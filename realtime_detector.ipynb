{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "import itertools\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Pre-Requisite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model and class target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hands detector\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "#Model Classifier\n",
    "model = tf.keras.models.load_model(\"models/bestModel_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define target class\n",
    "class_names = {\n",
    "    0:\"close\",\n",
    "    1:\"open\",\n",
    "    2:\"slide left\",\n",
    "    3:\"slide right\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to PreProcess and Annotate image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get coordinate of bounding box\n",
    "def calc_bounding_rect(image, landmarks): \n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_array = np.empty((0, 2), int)\n",
    "\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "\n",
    "        landmark_point = [np.array((landmark_x, landmark_y))]\n",
    "\n",
    "        landmark_array = np.append(landmark_array, landmark_point, axis=0)\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(landmark_array)\n",
    "\n",
    "    return [x, y, x + w, y + h]\n",
    "\n",
    "#calculate coordinate of each hand keypoints respective to image pixels\n",
    "def calc_landmark_list(image, landmarks): \n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_point = []\n",
    "\n",
    "    # Keypoint\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        # landmark_z = landmark.z\n",
    "\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "\n",
    "    return landmark_point\n",
    "\n",
    "\n",
    "#calculate coordinate of each hand keypoints respective to bounding box and normalize result\n",
    "def pre_process_landmark(landmark_list): \n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
    "\n",
    "    # Convert to a one-dimensional list\n",
    "    temp_landmark_list = list(\n",
    "        itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    # Normalization\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / max_value\n",
    "\n",
    "    temp_landmark_list = list(map(normalize_, temp_landmark_list))\n",
    "\n",
    "    return temp_landmark_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for drawing box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion to draw bounding box\n",
    "def draw_bounding_rect(use_brect, image, brect, text):\n",
    "    if use_brect:\n",
    "        # Outer rectangle\n",
    "        cv2.rectangle(image, (brect[0], brect[1]), (brect[2], brect[3]),\n",
    "                     (242, 147, 244), 2)\n",
    "    \n",
    "        cv2.rectangle(image, (brect[0], brect[1]), (brect[2], brect[1] - 22),\n",
    "                 (242, 147, 244), -1)\n",
    "        cv2.putText(image, str(text), (brect[0] + 5, brect[1] - 4),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Time Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build camera\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "#start realtime inference\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5 ) as hands:\n",
    "\n",
    "    while cam.isOpened():\n",
    "        #read frames\n",
    "        ret, frame = cam.read()\n",
    "        frame.flags.writeable = False\n",
    "\n",
    "        image = cv2.flip((cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)),1) \n",
    "        results = hands.process(image)\n",
    "\n",
    "        annotated_image = image.copy()\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            \n",
    "            for hand_landmarks, handedness in zip(results.multi_hand_landmarks,results.multi_handedness):\n",
    "\n",
    "                #find out box coordinate\n",
    "                boundary = calc_bounding_rect(image, hand_landmarks)\n",
    "\n",
    "                #calculate keypoints coordinate relative 0 keypoints(bottom of palm)\n",
    "                landmark_list = calc_landmark_list(image,hand_landmarks)\n",
    "                relative_landmark = pre_process_landmark(landmark_list)\n",
    "\n",
    "                #prediction the target\n",
    "                y = model.predict(np.expand_dims(relative_landmark, axis=0))\n",
    "                label = class_names[np.argmax(y)]\n",
    "\n",
    "            \n",
    "                #draw box coordinate\n",
    "                boundary = draw_bounding_rect(True , annotated_image, boundary, label)\n",
    "\n",
    "                mp_drawing.draw_landmarks(\n",
    "                        annotated_image,\n",
    "                        hand_landmarks,\n",
    "                        mp_hands.HAND_CONNECTIONS,\n",
    "                        mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                        mp_drawing_styles.get_default_hand_connections_style())\n",
    "                \n",
    "\n",
    "        #show the frames into the screen\n",
    "        annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imshow(\"Hand Pose Detection\", annotated_image)\n",
    "\n",
    "        #Break for stop the webcam process\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break   \n",
    "    \n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a28d050710e9fabbbd02a80b3cf3361a45fa3ba2ad7c4831274dc3ad00166d05"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
