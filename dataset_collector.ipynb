{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import PIL\n",
    "import os\n",
    "import copy\n",
    "import itertools\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter\n",
    "src_path = \"dataset/slideleft/\"\n",
    "aug_path = \"tmp/augmented_image/slideleft/\"\n",
    "img_dir = os.listdir(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create augmented picture\n",
    "\n",
    "for file in img_dir:\n",
    "        datagen = ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True,\n",
    "                brightness_range= [0.008,0.1],\n",
    "                fill_mode='nearest')\n",
    "\n",
    "        img = load_img(os.path.join(src_path,file))  # this is a PIL image\n",
    "        x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "        x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "        # the .flow() command below generates batches of randomly transformed images\n",
    "        # and saves the results to the `preview/` directory\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1,\n",
    "                                save_to_dir=aug_path, save_prefix='aug', save_format='png'):\n",
    "                i += 1\n",
    "                if i > 7:\n",
    "                        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Pre-Requisite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define mediapipe hand detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mediapipe detector\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to PreProcess landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get coordinate box of hand\n",
    "def calc_bounding_rect(image, landmarks): \n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_array = np.empty((0, 2), int)\n",
    "\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "\n",
    "        landmark_point = [np.array((landmark_x, landmark_y))]\n",
    "\n",
    "        landmark_array = np.append(landmark_array, landmark_point, axis=0)\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(landmark_array)\n",
    "\n",
    "    return [x, y, x + w, y + h]\n",
    "\n",
    "#get coordinate of x and y of each keypoints of hands\n",
    "def calc_landmark_list(image, landmarks): \n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_point = []\n",
    "\n",
    "    # Keypoint\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        # landmark_z = landmark.z\n",
    "\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "\n",
    "    return landmark_point\n",
    "\n",
    "\n",
    "#convert coordinate of keypoints into respective of bottom of palm (0,0)\n",
    "def pre_process_landmark(landmark_list): \n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
    "\n",
    "    # Convert to a one-dimensional list\n",
    "    temp_landmark_list = list(\n",
    "        itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    # Normalization\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / max_value\n",
    "\n",
    "    temp_landmark_list = list(map(normalize_, temp_landmark_list))\n",
    "\n",
    "    return temp_landmark_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_rect(use_brect, image, brect):\n",
    "    if use_brect:\n",
    "        # Outer rectangle\n",
    "        cv2.rectangle(image, (brect[0], brect[1]), (brect[2], brect[3]),\n",
    "                     (0, 0, 0), 1)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to append keypoints into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_csv(filename, listvalue):\n",
    "    if os.path.isfile(filename):\n",
    "        with open(filename, 'a+', newline=\"\") as write_obj:\n",
    "            csv_writer= writer(write_obj)\n",
    "            csv_writer.writerow(listvalue)\n",
    "    else:\n",
    "        return \"Create your empty csv format file first!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect hand keypoints from picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter\n",
    "data_path = \"junk/temp2/slideright/\"\n",
    "X_csvpath = \"datasetcsv/landmark.csv\"\n",
    "y_csvpath = \"datasetcsv/label.csv\"\n",
    "annotated_path = \"tmp/annotated_image2/slideright/\"\n",
    "target = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For static images:\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=True,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.2) as hands:\n",
    "\n",
    "  img_list = os.listdir(data_path)\n",
    "\n",
    "  for idx, file in enumerate(img_list):\n",
    "    # Read an image, flip it around y-axis for correct handedness output (see\n",
    "    # above).\n",
    "    image = cv2.flip(cv2.imread(os.path.join(data_path,file)), 1)\n",
    "    \n",
    "    # Convert the BGR image to RGB before processing.\n",
    "    results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    annotated_image = image.copy()\n",
    "\n",
    "    if results.multi_hand_landmarks :\n",
    "      for hand_landmarks in results.multi_hand_landmarks:\n",
    "        #find out box coordinate\n",
    "        boundary = calc_bounding_rect(image, hand_landmarks)\n",
    "\n",
    "        #calculate keypoints coordinate relative 0 keypoints(bottom of palm)\n",
    "        landmark_list = calc_landmark_list(image,hand_landmarks)\n",
    "        relative_landmark = pre_process_landmark(landmark_list)\n",
    "\n",
    "        #append result to csv\n",
    "        append_to_csv(X_csvpath, relative_landmark)\n",
    "        append_to_csv(y_csvpath, [target])\n",
    "            \n",
    "        #draw box coordinate\n",
    "        boundary = draw_bounding_rect(True , annotated_image, boundary)\n",
    "\n",
    "        mp_drawing.draw_landmarks(\n",
    "              annotated_image,\n",
    "              hand_landmarks,\n",
    "              mp_hands.HAND_CONNECTIONS,\n",
    "              mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "              mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "    cv2.imwrite(\n",
    "        annotated_path + str(idx) + '.png', cv2.flip(annotated_image, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a28d050710e9fabbbd02a80b3cf3361a45fa3ba2ad7c4831274dc3ad00166d05"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
